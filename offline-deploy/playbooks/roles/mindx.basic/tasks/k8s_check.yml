- name: check k8s config exits
  shell: if [ -d /etc/cni ] || [ -d /etc/kubernetes ] || [ -d /etc/systemd/system/kubelet.service.d ];then echo 1;else echo 0;fi
  register: k8s_exists

- name: message
  debug:
    msg: "[WARNING] The configuration file directory for k8s exists on the system"
  changed_when: true
  when: k8s_exists.stdout == "1"

# 检查master节点必须存在k8s_api_server_ip的ip
- name: check k8s_api_server_ip must configured
  fail:
    msg: "k8s_api_server_ip must be configured in inventory_file"
  when:
    - k8s_api_server_ip is not defined or k8s_api_server_ip | trim == ''
    - inventory_hostname in groups["master"]

# 检查master节点k8s_api_server_ip必须配置到网卡上
- name: check k8s_api_server_ip must exists
  shell:
    cmd:
      is_exist=$(ifconfig | grep -w {{ k8s_api_server_ip }} | wc -l);
      if [ $is_exist -eq 0 ]; then echo "{{ not_match }}"; else echo "match"; fi
  register: api_ip_correct
  when:
    - k8s_api_server_ip is defined and k8s_api_server_ip | trim != ''
    - inventory_hostname in groups["master"]

- name: failed when k8s_api_server_ip not exists on master
  fail:
    msg: "k8s_api_server_ip must be a exists IP on master node"
  when:
    - inventory_hostname in groups["master"]
    - "api_ip_correct is defined and STDOUT_KEY in api_ip_correct"
    - "api_ip_correct.stdout == not_match"

# 检查多master场景下kube_interface的网卡必须存在
- name: check kube_interface must exists
  shell:
    cmd:
      is_exist=$(ifconfig | grep -w {{ kube_interface }} | wc -l);
      if [ $is_exist -eq 0 ]; then echo "{{ not_match }}"; else echo "match"; fi
  register: interface_correct
  when:
    - "groups['master'] | length > 1"
    - kube_interface is defined and kube_interface | trim != ''
    - inventory_hostname in groups["master"]

- name: failed when kube_interface not exists on master
  fail:
    msg: "kube_interface must be a exists network interface on master node"
  when:
    - inventory_hostname in groups["master"]
    - "groups['master'] | length > 1"
    - "interface_correct is defined and STDOUT_KEY in interface_correct"
    - "interface_correct.stdout == not_match"

# 如果需要安装K8s，检查集群网络配置是否冲突
- name: register value k8s pod network cird - master k8s_api_server_ip
  shell:
    cmd:
      /bin/bash -c "if [[ {{ hostvars[item].k8s_api_server_ip }} =~ 192.168.*.* ]] && [[ {{ POD_NETWORK_CIDR }} =~ 192.168.*.* ]]; then echo "{{ not_match }}"; else echo "{{ match }}"; fi"
  register: master_cird_status
  loop: "{{ groups['master'] }}"
  changed_when: false
  when:
    - inventory_hostname == "localhost"

- name: check k8s pod network cird - master k8s_api_server_ip
  fail:
    msg: "please modify POD_NETWORK_CIDR param in {{ hostvars['localhost'].ansible_inventory_sources[0] }} on install command execution node, change it to other private network, for example 10.0.0.0/16"
  loop: "{{ master_cird_status['results'] }}"
  when:
    - inventory_hostname == "localhost"
    - master_cird_status is defined and STDOUT_KEY in item and item.stdout == not_match

- name: register value k8s pod network cird - worker
  shell:
    cmd:
      /bin/bash -c "if [[ {{ item }} =~ 192.168.*.* ]] && [[ {{ POD_NETWORK_CIDR }} =~ 192.168.*.* ]]; then echo "{{ not_match }}"; else echo "{{ match }}"; fi"
  register: worker_cird_status
  loop: "{{ groups['worker'] }}"
  changed_when: false
  when:
    - inventory_hostname == "localhost"

- name: check k8s pod network cird - worker
  fail:
    msg: "please modify POD_NETWORK_CIDR param in {{ hostvars['localhost'].ansible_inventory_sources[0] }} on install command execution node, change it to other private network, for example 10.0.0.0/16"
  loop: "{{ worker_cird_status['results'] }}"
  when:
    - inventory_hostname == "localhost"
    - worker_cird_status is defined and STDOUT_KEY in item and item.stdout == not_match

- name: POD_NETWORK_CIDR and KUBE_VIP
  fail:
    msg: "please modify POD_NETWORK_CIDR param in {{ hostvars['localhost'].ansible_inventory_sources[0] }} on install command execution node, change it to other private network, for example 10.0.0.0/16"
  when:
    - inventory_hostname == "localhost"
    - "groups['master'] | length > 1"
    - KUBE_VIP != "" and KUBE_VIP.startswith("192.168")
    - POD_NETWORK_CIDR != "" and POD_NETWORK_CIDR.startswith("192.168")

- name: include k8s_status_check
  include_tasks: ./k8s_status_check.yml
  when:
    - inventory_hostname != "localhost"




